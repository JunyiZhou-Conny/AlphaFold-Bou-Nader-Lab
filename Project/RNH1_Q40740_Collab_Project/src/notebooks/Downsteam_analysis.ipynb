{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        fold_group  job_number target_protein  iptm   ptm  ranking_score  \\\n",
      "126  folds_120_149         126         q01560  0.65  0.50           0.82   \n",
      "359  folds_330_359         359         p13433  0.60  0.70           0.68   \n",
      "382  folds_360_389         382         q06406  0.83  0.67           0.87   \n",
      "432  folds_420_449         432         q3e835  0.72  0.52           0.74   \n",
      "573  folds_570_599         573         p40204  0.70  0.63           0.75   \n",
      "\n",
      "     fraction_disordered  has_clash  num_recycles  chain_iptm_0  ...  \\\n",
      "126                 0.40          0            10          0.65  ...   \n",
      "359                 0.12          0            10          0.60  ...   \n",
      "382                 0.14          0            10          0.83  ...   \n",
      "432                 0.12          0            10          0.72  ...   \n",
      "573                 0.12          0            10          0.70  ...   \n",
      "\n",
      "     chain_ptm_0  chain_ptm_1  chain_pair_iptm_00  chain_pair_iptm_01  \\\n",
      "126         0.64         0.31                0.64                0.65   \n",
      "359         0.58         0.74                0.58                0.60   \n",
      "382         0.63         0.75                0.63                0.83   \n",
      "432         0.61         0.60                0.61                0.72   \n",
      "573         0.62         0.72                0.62                0.70   \n",
      "\n",
      "     chain_pair_iptm_10  chain_pair_iptm_11  chain_pair_pae_min_00  \\\n",
      "126                0.65                0.31                   0.76   \n",
      "359                0.60                0.74                   0.76   \n",
      "382                0.83                0.75                   0.76   \n",
      "432                0.72                0.60                   0.76   \n",
      "573                0.70                0.72                   0.76   \n",
      "\n",
      "     chain_pair_pae_min_01  chain_pair_pae_min_10  chain_pair_pae_min_11  \n",
      "126                   1.21                   1.23                   0.76  \n",
      "359                   3.99                   5.29                   0.76  \n",
      "382                   1.29                   1.35                   0.76  \n",
      "432                   3.37                   7.43                   0.76  \n",
      "573                   4.45                   4.73                   0.76  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "                jobs  iptm_ptm      iptm  pDockQ/mpDockQ  \\\n",
      "0  Q04740_and_Q07688  0.798025  0.828290        0.256014   \n",
      "1  Q04740_and_P39990  0.748798  0.773920        0.220476   \n",
      "2  Q04740_and_P32381  0.738497  0.743964        0.306242   \n",
      "3  Q04740_and_P06780  0.712525  0.725516        0.269554   \n",
      "4  Q04740_and_Q04951  0.692783  0.694635        0.471625   \n",
      "\n",
      "  average_interface_pae average_interface_plddt binding_energy interface  \\\n",
      "0           7.157922912             70.05185185   -2795.131981       B_C   \n",
      "1           6.798353293             70.83880342    -3145.06492       B_C   \n",
      "2           9.871798365             65.58212329   -4420.934524       B_C   \n",
      "3           8.790899123             73.09880952   -3443.361871       B_C   \n",
      "4           8.477083333             74.33919355   -2953.140934       B_C   \n",
      "\n",
      "   Num_intf_residues  Polar  Hydrophobic  Charged  contact_pairs   sc   hb  \\\n",
      "0                NaN    NaN          NaN      NaN            NaN  NaN  NaN   \n",
      "1                NaN    NaN          NaN      NaN            NaN  NaN  NaN   \n",
      "2                NaN    NaN          NaN      NaN            NaN  NaN  NaN   \n",
      "3                NaN    NaN          NaN      NaN            NaN  NaN  NaN   \n",
      "4                NaN    NaN          NaN      NaN            NaN  NaN  NaN   \n",
      "\n",
      "    sb   int_solv_en   int_area  pi_score  \n",
      "0  NaN           NaN        NaN       NaN  \n",
      "1  NaN           NaN        NaN       NaN  \n",
      "2  NaN           NaN        NaN       NaN  \n",
      "3  NaN           NaN        NaN       NaN  \n",
      "4  NaN           NaN        NaN       NaN  \n"
     ]
    }
   ],
   "source": [
    "# I wanna import 2 csv files and filter them based on a few criteria\n",
    "# Let us start importing th files\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "AF3_data = pd.read_csv('/Users/conny/Desktop/AlphaFold/Downstream_Analysis/AF3_Summary_Stats.csv')\n",
    "AFP_data = pd.read_csv('/Users/conny/Desktop/AlphaFold/Downstream_Analysis/afp_predictions_with_good_interpae_cutoff_100.csv')\n",
    "#print(AF3_data.head())\n",
    "#print(AFP_data.head())\n",
    "#iptm ptm for AF3\n",
    "#iptm_ptm iptm for AFP\n",
    "\n",
    "#filtering the data based on the criteria\n",
    "#Inside the AF3_data, iptm should be greater than or equal to 0.6 and ptm should be greater than or equal to 0.5\n",
    "#Inside the AFP_data, iptm_ptm should be greater than or equal to 0.5 and ptm_ptm should be greater than or equal to 0.5\n",
    "\n",
    "#filtering the data based on the criteria\n",
    "AF3_data_filtered = AF3_data[(AF3_data['iptm'] >= 0.6) & (AF3_data['ptm'] >= 0.5)]\n",
    "AFP_data_filtered = AFP_data[(AFP_data['iptm_ptm'] >= 0.5) & (AFP_data['iptm'] >= 0.6)]\n",
    "\n",
    "print(AF3_data_filtered.head())\n",
    "print(AFP_data_filtered.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AF3_data columns:\n",
      "['fold_group', 'job_number', 'target_protein', 'iptm', 'ptm', 'ranking_score', 'fraction_disordered', 'has_clash', 'num_recycles', 'chain_iptm_0', 'chain_iptm_1', 'chain_ptm_0', 'chain_ptm_1', 'chain_pair_iptm_00', 'chain_pair_iptm_01', 'chain_pair_iptm_10', 'chain_pair_iptm_11', 'chain_pair_pae_min_00', 'chain_pair_pae_min_01', 'chain_pair_pae_min_10', 'chain_pair_pae_min_11']\n",
      "\n",
      "AFP_data columns:\n",
      "['jobs', 'iptm_ptm', 'iptm', 'pDockQ/mpDockQ', 'average_interface_pae', 'average_interface_plddt', 'binding_energy', 'interface', 'Num_intf_residues', 'Polar', 'Hydrophobic', 'Charged', 'contact_pairs', ' sc', ' hb', ' sb', ' int_solv_en', ' int_area', 'pi_score']\n"
     ]
    }
   ],
   "source": [
    "# I wanna import 2 csv files and filter them based on a few criteria\n",
    "# Let us start importing th files\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "AF3_data = pd.read_csv('/Users/conny/Desktop/AlphaFold/Downstream_Analysis/AF3_Summary_Stats.csv')\n",
    "AFP_data = pd.read_csv('/Users/conny/Desktop/AlphaFold/Downstream_Analysis/afp_predictions_with_good_interpae_cutoff_100.csv')\n",
    "\n",
    "# Display column information for both dataframes\n",
    "print(\"AF3_data columns:\")\n",
    "print(AF3_data.columns.tolist())\n",
    "print(\"\\nAFP_data columns:\")\n",
    "print(AFP_data.columns.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataframe shape: (1843, 23)\n",
      "\n",
      "First few rows of merged data:\n",
      "  target_protein  AF3_iptm  AFP_iptm  AF3_ranking_score  AFP_iptm_ptm  \\\n",
      "0         q04740      0.15  0.190817               0.27      0.233591   \n",
      "1         p32445      0.15  0.172676               0.31      0.236131   \n",
      "2         p05755      0.14  0.156719               0.28      0.210596   \n",
      "3         o13516      0.16  0.181239               0.30      0.233499   \n",
      "4         p0cx45      0.07  0.150233               0.17      0.209779   \n",
      "\n",
      "   AF3_ptm               jobs  pDockQ/mpDockQ average_interface_pae  \\\n",
      "0     0.40  Q04740_and_Q04740        0.028452           23.89935484   \n",
      "1     0.48  Q04740_and_P32445        0.139601           23.72739274   \n",
      "2     0.41  Q04740_and_P05755        0.021414           25.32340426   \n",
      "3     0.41  Q04740_and_O13516        0.030715           24.67513369   \n",
      "4     0.35  Q04740_and_P0CX45        0.000000           25.68333333   \n",
      "\n",
      "  average_interface_plddt  ... Polar Hydrophobic  Charged  contact_pairs   sc  \\\n",
      "0             68.24301075  ...   NaN         NaN      NaN            NaN  NaN   \n",
      "1                   54.54  ...   NaN         NaN      NaN            NaN  NaN   \n",
      "2             68.93683333  ...   NaN         NaN      NaN            NaN  NaN   \n",
      "3             58.47180952  ...   NaN         NaN      NaN            NaN  NaN   \n",
      "4             73.35384615  ...   NaN         NaN      NaN            NaN  NaN   \n",
      "\n",
      "    hb   sb   int_solv_en   int_area  pi_score  \n",
      "0  NaN  NaN           NaN        NaN       NaN  \n",
      "1  NaN  NaN           NaN        NaN       NaN  \n",
      "2  NaN  NaN           NaN        NaN       NaN  \n",
      "3  NaN  NaN           NaN        NaN       NaN  \n",
      "4  NaN  NaN           NaN        NaN       NaN  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Process and merge the dataframes\n",
    "\n",
    "# Extract the second protein from AFP's jobs column and convert to lowercase\n",
    "AFP_data['target_protein'] = AFP_data['jobs'].str.split('_and_').str[1].str.lower()\n",
    "\n",
    "# Rename columns to avoid confusion\n",
    "AF3_data = AF3_data.rename(columns={\n",
    "    'iptm': 'AF3_iptm',\n",
    "    'ptm': 'AF3_ptm',\n",
    "    'ranking_score': 'AF3_ranking_score'\n",
    "})\n",
    "\n",
    "AFP_data = AFP_data.rename(columns={\n",
    "    'iptm_ptm': 'AFP_iptm_ptm',\n",
    "    'iptm': 'AFP_iptm'\n",
    "})\n",
    "\n",
    "# Merge the dataframes\n",
    "merged_data = pd.merge(\n",
    "    AF3_data[['target_protein', 'AF3_iptm', 'AF3_ptm', 'AF3_ranking_score']],\n",
    "    AFP_data,\n",
    "    on='target_protein',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Reorder columns to put important metrics first\n",
    "important_columns = ['target_protein', 'AF3_iptm', 'AFP_iptm', 'AF3_ranking_score', 'AFP_iptm_ptm', 'AF3_ptm']\n",
    "remaining_columns = [col for col in merged_data.columns if col not in important_columns]\n",
    "merged_data = merged_data[important_columns + remaining_columns]\n",
    "\n",
    "# Display the merged dataframe\n",
    "print(\"Merged dataframe shape:\", merged_data.shape)\n",
    "print(\"\\nFirst few rows of merged data:\")\n",
    "print(merged_data.head())\n",
    "\n",
    "# Save the merged dataframe to a new CSV file\n",
    "merged_data.to_csv('/Users/conny/Desktop/AlphaFold/Downstream_Analysis/merged_AF3_AFP_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl.styles import PatternFill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the target protein lists\n",
    "with open('/Users/conny/Desktop/AlphaFold/Downstream_Analysis/af3_target_names.txt', 'r') as f:\n",
    "    af3_targets = [line.strip().lower() for line in f.readlines()]\n",
    "\n",
    "with open('/Users/conny/Desktop/AlphaFold/Downstream_Analysis/afp_target_names.txt', 'r') as f:\n",
    "    afp_targets = [line.strip().lower() for line in f.readlines()]\n",
    "\n",
    "# Create a new column to indicate the source\n",
    "merged_data['source'] = 'None'\n",
    "merged_data.loc[merged_data['target_protein'].isin(af3_targets), 'source'] = 'AF3'\n",
    "merged_data.loc[merged_data['target_protein'].isin(afp_targets), 'source'] = 'AFP'\n",
    "\n",
    "# Save to Excel with conditional formatting\n",
    "with pd.ExcelWriter('/Users/conny/Desktop/AlphaFold/Downstream_Analysis/merged_AF3_AFP_data_highlighted.xlsx', engine='openpyxl') as writer:\n",
    "    merged_data.to_excel(writer, index=False, sheet_name='Merged Data')\n",
    "    \n",
    "    # Get the worksheet\n",
    "    worksheet = writer.sheets['Merged Data']\n",
    "    \n",
    "    # Create yellow fill for AF3\n",
    "    yellow_fill = PatternFill(start_color='FFFF00', end_color='FFFF00', fill_type='solid')\n",
    "    # Create blue fill for AFP\n",
    "    blue_fill = PatternFill(start_color='ADD8E6', end_color='ADD8E6', fill_type='solid')\n",
    "    \n",
    "    # Apply the formatting\n",
    "    for row in range(2, len(merged_data) + 2):  # +2 because Excel is 1-based and we have a header\n",
    "        source = merged_data.iloc[row-2]['source']\n",
    "        if source == 'AF3':\n",
    "            for col in range(1, len(merged_data.columns) + 1):\n",
    "                worksheet.cell(row=row, column=col).fill = yellow_fill\n",
    "        elif source == 'AFP':\n",
    "            for col in range(1, len(merged_data.columns) + 1):\n",
    "                worksheet.cell(row=row, column=col).fill = blue_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of top hits: 55\n",
      "\n",
      "First few rows of top hits:\n",
      "     target_protein  AF3_iptm  AFP_iptm  AF3_ranking_score  AFP_iptm_ptm  \\\n",
      "1306         p00890      0.67  0.144050               0.73      0.229171   \n",
      "1408         p03965      0.66  0.407143               0.70      0.488206   \n",
      "356          p13433      0.60  0.250298               0.68      0.327945   \n",
      "1079         p14065      0.70  0.195701               0.74      0.261734   \n",
      "1541         p15496      0.68  0.214851               0.73      0.270626   \n",
      "\n",
      "      AF3_ptm               jobs  pDockQ/mpDockQ average_interface_pae  \\\n",
      "1306     0.60  Q04740_and_P00890        0.121465           27.35724138   \n",
      "1408     0.78  Q04740_and_P03965        0.133583           20.14066667   \n",
      "356      0.70  Q04740_and_P13433        0.027713            26.6147482   \n",
      "1079     0.70  Q04740_and_P14065        0.245983           24.37622081   \n",
      "1541     0.66  Q04740_and_P15496        0.169486              23.82625   \n",
      "\n",
      "     average_interface_plddt  ... Hydrophobic Charged  contact_pairs   sc  \\\n",
      "1306             64.91300885  ...         NaN     NaN            NaN  NaN   \n",
      "1408                 66.9955  ...         NaN     NaN            NaN  NaN   \n",
      "356              56.35118421  ...         NaN     NaN            NaN  NaN   \n",
      "1079             69.01207143  ...         NaN     NaN            NaN  NaN   \n",
      "1541             64.27520231  ...         NaN     NaN            NaN  NaN   \n",
      "\n",
      "       hb   sb   int_solv_en   int_area  pi_score  source  \n",
      "1306  NaN  NaN           NaN        NaN       NaN     AF3  \n",
      "1408  NaN  NaN           NaN        NaN       NaN     AF3  \n",
      "356   NaN  NaN           NaN        NaN       NaN     AF3  \n",
      "1079  NaN  NaN           NaN        NaN       NaN     AF3  \n",
      "1541  NaN  NaN           NaN        NaN       NaN     AF3  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nm/l2c6vmjx5jqc1c8c45pgqkh00000gn/T/ipykernel_97413/353552471.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top_hits_data['source'] = 'None'\n"
     ]
    }
   ],
   "source": [
    "# Filter the merged data to only include top hits\n",
    "top_hits_data = merged_data[\n",
    "    merged_data['target_protein'].isin(af3_targets + afp_targets)\n",
    "]\n",
    "\n",
    "# Add a source column to indicate whether it's from AF3 or AFP\n",
    "top_hits_data['source'] = 'None'\n",
    "top_hits_data.loc[top_hits_data['target_protein'].isin(af3_targets), 'source'] = 'AF3'\n",
    "top_hits_data.loc[top_hits_data['target_protein'].isin(afp_targets), 'source'] = 'AFP'\n",
    "\n",
    "# Sort by source and target protein\n",
    "top_hits_data = top_hits_data.sort_values(['source', 'target_protein'])\n",
    "\n",
    "# Save to Excel\n",
    "top_hits_data.to_excel('/Users/conny/Desktop/AlphaFold/Downstream_Analysis/top_hits_AF3_AFP.xlsx', index=False)\n",
    "\n",
    "# Display the shape and first few rows\n",
    "print(f\"Number of top hits: {len(top_hits_data)}\")\n",
    "print(\"\\nFirst few rows of top hits:\")\n",
    "print(top_hits_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "# Parse the FASTA file into a dictionary: {protein_id: sequence}\n",
    "fasta_path = \"/Users/conny/Desktop/AlphaFold/unique_protein_sequences.fasta\"\n",
    "seq_dict = {record.id.upper(): str(record.seq) for record in SeqIO.parse(fasta_path, \"fasta\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your existing code ...\n",
    "af3_targets = set(pd.read_excel('af3_target_names.xlsx')['Target_Names'])\n",
    "afp_targets = set(pd.read_excel('afp_target_names.xlsx')['Target_Names'])\n",
    "\n",
    "overlap = af3_targets.intersection(afp_targets)\n",
    "only_af3 = af3_targets - afp_targets\n",
    "only_afp = afp_targets - af3_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def make_df(ids, group_name):\n",
    "    return pd.DataFrame({\n",
    "        f\"{group_name}_ID\": sorted(ids),\n",
    "        f\"{group_name}_Sequence\": [seq_dict.get(pid, \"NOT_FOUND\") for pid in sorted(ids)]\n",
    "    })\n",
    "\n",
    "df_only_af3 = make_df(only_af3, \"Only_AF3\")\n",
    "df_only_afp = make_df(only_afp, \"Only_AFP\")\n",
    "df_overlap = make_df(overlap, \"Overlap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(\"overlap_analysis_with_sequences.xlsx\") as writer:\n",
    "    df_only_af3.to_excel(writer, sheet_name=\"Only_AF3\", index=False)\n",
    "    df_only_afp.to_excel(writer, sheet_name=\"Only_AFP\", index=False)\n",
    "    df_overlap.to_excel(writer, sheet_name=\"Overlap\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
